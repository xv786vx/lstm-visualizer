# -*- coding: utf-8 -*-
"""lstm_strategy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y50I3hDfcc55mXrFq70Ukbm15e1gLC-V
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install yfinance
# %pip install pandas
# %pip install image
# %pip install matplotlib
# %pip install numpy
# %pip install tensorflow
# %pip install joblib


import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import joblib
from joblib import dump, load
import os
import random

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.losses import MeanSquaredError
from sklearn.metrics import mean_squared_error, r2_score

"""## Strategy #1 Part 1: Preprocessing data

"""

class StockDataFetcher:
    """Fetches stock data and creates features for model training"""
    def calc_technical_indicators(stock_data):
        """Calculate technical indicators for a stock DataFrame"""
        # RSI
        delta = stock_data['Close'].diff(1)
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14).mean()
        avg_loss = loss.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        stock_data['RSI'] = 100 - (100 / (1 + rs))

        # Other indicators
        stock_data['Daily Return'] = stock_data['Close'].pct_change()
        stock_data['50MA'] = stock_data['Close'].rolling(window=50).mean()
        stock_data['200MA'] = stock_data['Close'].rolling(window=200).mean()
        stock_data['Volatility'] = stock_data['Daily Return'].rolling(window=10).std()
        stock_data['20EMA'] = stock_data['Close'].ewm(span=20, adjust=False).mean()
        stock_data['VWAP'] = (((stock_data['High'] + stock_data['Low'] + stock_data['Close']) / 3)
                             * stock_data['Volume']).cumsum() / stock_data['Volume'].cumsum()

        return stock_data

class LSTMStockPredictor:
    """Main class for stock prediction using LSTM, Dense, Regularization layers"""
    def __init__(self, model_path, seq_length):
        self.model_path = model_path
        self.seq_length = seq_length
        self.scalers = {}
        self.model = None
        self.features = ['Close', 'Daily Return', '50MA', '200MA',
                        'Volatility', 'RSI', 'VWAP', '20EMA']
        self.training_tickers = None
        self.model_metadata_path = model_path.replace('.keras', '_metadata.json')

        # Load model and check if it matches current tickers
        self._load_model_if_compatible()

    def _load_model_if_compatible(self):
        """Load model only if it exists and was trained on compatible tickers"""
        if os.path.exists(self.model_path) and os.path.exists(self.model_metadata_path):
            try:
                import json
                with open(self.model_metadata_path, 'r') as f:
                    metadata = json.load(f)
                    self.training_tickers = metadata.get('training_tickers', [])
                    print(f"Found existing model trained on: {self.training_tickers}")
                    
                self.model = load_model(self.model_path)
                print(f"Loaded existing model from {self.model_path}")
            except Exception as e:
                print(f"Error loading model metadata: {e}")
                self._clear_model()
        else:
            self.model = None
            self.training_tickers = None

    def _clear_model(self):
        """Clear existing model and metadata files"""
        if os.path.exists(self.model_path):
            os.remove(self.model_path)
            print(f"Removed incompatible model: {self.model_path}")
        if os.path.exists(self.model_metadata_path):
            os.remove(self.model_metadata_path)
            print(f"Removed model metadata: {self.model_metadata_path}")
        self.model = None
        self.training_tickers = None

    def _save_model_metadata(self, tickers):
        """Save metadata about the model including training tickers"""
        import json
        metadata = {
            'training_tickers': sorted(tickers),  # Sort for consistent comparison
            'seq_length': self.seq_length,
            'features': self.features,
            'created_at': str(pd.Timestamp.now())
        }
        with open(self.model_metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        print(f"Saved model metadata to {self.model_metadata_path}")

    def _tickers_match(self, new_tickers):
        """Check if new tickers match the ones the model was trained on"""
        if self.training_tickers is None:
            return False
        return sorted(new_tickers) == sorted(self.training_tickers)


    def fetch_and_prepare_data(self, tickers, start_date, end_date):
        """Fetch and prepare stock data for multiple tickers"""
        all_data = []
        for ticker in tickers:
            # Fetch data
            stock = yf.download(ticker, start=start_date, end=end_date)
            stock.columns = stock.columns.get_level_values(0)  # Remove multi-level columns
            stock['Ticker'] = ticker

            # Calculate indicators
            stock = StockDataFetcher.calc_technical_indicators(stock)
            stock.dropna(inplace=True)
            all_data.append(stock)

        combined_data = pd.concat(all_data, axis=0)
        return combined_data.reset_index()


    def normalize_data(self, data):
        """Normalize data by stock"""
        normalized_data = data.copy()  # Create a copy to avoid modifying original data

        for ticker, group in normalized_data.groupby('Ticker'):
            if ticker not in self.scalers:
                print(f"Creating new scaler for {ticker}")
                scaler = StandardScaler()
                # Fit the scaler on the features
                scaler.fit(group[self.features])
                self.scalers[ticker] = scaler
            else:
                print(f"Using existing scaler for {ticker}")

            # Transform the data
            normalized_values = self.scalers[ticker].transform(group[self.features])
            normalized_data.loc[group.index, self.features] = normalized_values

        return normalized_data

    def create_sequences(self, data, all_tickers, original_close=None):
        """Create sequences for LSTM input"""
        X, y, dates = [], [], []

        # Create consistent one-hot encoding
        ticker_to_idx = {t: idx for idx, t in enumerate(all_tickers)}
        one_hot_size = len(all_tickers)

        for ticker in data['Ticker'].unique():
            group = data[data['Ticker'] == ticker]
            values = group[self.features].values
            close_prices = original_close[original_close.index.isin(group.index)] if original_close is not None else group['Close']

            for i in range(len(values) - self.seq_length):
                sequence = values[i:i + self.seq_length]
                target = close_prices.iloc[i + self.seq_length]
                dates.append(group.index[i + self.seq_length])

                # Create one-hot encoding
                ticker_one_hot = np.zeros(one_hot_size)
                ticker_one_hot[ticker_to_idx[ticker]] = 1

                # Stack features with one-hot encoding
                sequence_with_ticker = np.column_stack([sequence, np.tile(ticker_one_hot, (self.seq_length, 1))])
                X.append(sequence_with_ticker)
                y.append(target)

        return np.array(X), np.array(y), pd.DatetimeIndex(dates)

    def train_save_model(self, X, y, tickers):
      """Train and save the LSTM model"""
      print("\nChecking model compatibility...")
      
      # Check if we need to retrain
      if not self._tickers_match(tickers):
          if self.training_tickers is not None:
              print(f"Ticker mismatch! Previous: {self.training_tickers}, Current: {sorted(tickers)}")
              self._clear_model()
          else:
              print("No existing compatible model found.")
      
      # Split data regardless of whether we train or not
      split_idx = int(len(X) * 0.8)
      X_train, X_test = X[:split_idx], X[split_idx:]
      y_train, y_test = y[:split_idx], y[split_idx:]

      if self.model is not None and self._tickers_match(tickers):
          print(f"Using existing compatible model for tickers: {sorted(tickers)}")
      else:
          print("Training new model...")
          print(f"Input shape: {X.shape}")

          self.model = Sequential([
              LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
              Dropout(0.2),
              LSTM(32, return_sequences=False),
              Dropout(0.2),
              Dense(16, activation='relu'),
              Dense(1)
          ])
          self.model.compile(optimizer='adam', loss='mse')

          # Train model
          self.model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)
          self.model.save(self.model_path)
          self.training_tickers = sorted(tickers)
          self._save_model_metadata(tickers)
          print(f"Model saved to {self.model_path}")

      return X_test, y_test


    def backtest_stock(self, ticker, start_date, end_date, all_tickers):
        """Perform backtesting for a single ticker"""
        print(f"\nBacktesting {ticker}...")

        # Get and prepare data
        data = self.fetch_and_prepare_data([ticker], start_date, end_date)
        original_close = data['Close'].copy()
        normalized_data = self.normalize_data(data)

        # Create sequences using all tickers for consistent dimensions
        X, y, dates = self.create_sequences(normalized_data, all_tickers, original_close)

        if len(X) < self.seq_length + 32:
            print(f"Not enough data for {ticker}")
            return None

        # Split data for testing
        split_idx = int(len(X) * 0.8)
        X_test = X[split_idx:]
        y_test = y[split_idx:]
        test_dates = dates[split_idx:]

        print(f"Input shape: {X_test.shape}")  # Debug print

        # Make predictions
        predictions = self.model.predict(X_test, batch_size=32, verbose=0).flatten()

        dummy_array = np.zeros((len(predictions), len(self.features)))
        # Put predictions in the 'Close' price column position
        dummy_array[:, 0] = predictions
        # Inverse transform
        predictions = self.scalers[ticker].inverse_transform(dummy_array)[:, 0]

        # Create results DataFrame with portfolio management
        backtest_df = pd.DataFrame({
            'Date': test_dates,
            'Close': y_test,
            'Predicted': predictions,
            'Position': 0,
            'Cash': 10000,  # Initial cash
            'Holdings': 0,
            'Total_Value': 10000
        }).set_index('Date')

        # Generate trading signals and manage portfolio
        for i in range(1, len(backtest_df)):
            prev_cash = backtest_df['Cash'].iloc[i-1]
            prev_holdings = backtest_df['Holdings'].iloc[i-1]
            current_price = backtest_df['Close'].iloc[i]
            predicted_price = backtest_df['Predicted'].iloc[i]

            # Generate signal based on predicted price movement
            signal = 1 if predicted_price > current_price else 0

            # Execute trades based on signal
            if signal == 1 and prev_cash >= current_price:
                # Buy signal - invest all available cash
                shares_to_buy = prev_cash // current_price
                new_holdings = prev_holdings + shares_to_buy
                new_cash = prev_cash - (shares_to_buy * current_price)
            elif signal == 0 and prev_holdings > 0:
                # Sell signal - sell all holdings
                new_cash = prev_cash + (prev_holdings * current_price)
                new_holdings = 0
            else:
                # Hold current position
                new_cash = prev_cash
                new_holdings = prev_holdings

            # Calculate total portfolio value
            total_value = new_cash + (new_holdings * current_price)

            # Update DataFrame
            backtest_df.iloc[i, backtest_df.columns.get_loc('Cash')] = new_cash
            backtest_df.iloc[i, backtest_df.columns.get_loc('Holdings')] = new_holdings
            backtest_df.iloc[i, backtest_df.columns.get_loc('Total_Value')] = total_value
            backtest_df.iloc[i, backtest_df.columns.get_loc('Position')] = signal

        return backtest_df


    def plot_results(self, backtest_df, ticker, start_date, end_date, save_path=None):
      """Plot backtest results including price predictions and portfolio value"""
      # Set dark background style for better visibility
      plt.style.use('dark_background')
      fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
      
      # Set figure background to transparent
      fig.patch.set_alpha(0.0)

      # Plot 1: Price and Predictions
      ax1.plot(backtest_df.index, backtest_df['Close'],
              label='Actual', color='white', linewidth=2)
      ax1.plot(backtest_df.index, backtest_df['Predicted'],
              label='Predicted', color='#ff6b6b', linestyle='--', linewidth=2)
      ax1.set_title(f'{ticker} Price Prediction', color='white', fontsize=16, fontweight='bold')
      ax1.set_xlabel('Date', color='white', fontsize=12)
      ax1.set_ylabel('Price ($)', color='white', fontsize=12)
      ax1.legend(fontsize=12)
      ax1.grid(True, alpha=0.3)
      ax1.tick_params(colors='white')
      ax1.spines['bottom'].set_color('white')
      ax1.spines['top'].set_color('white')
      ax1.spines['right'].set_color('white')
      ax1.spines['left'].set_color('white')

      # Plot 2: Portfolio Value and Returns
      portfolio_value = backtest_df['Total_Value']
      market_value = backtest_df['Close'] / backtest_df['Close'].iloc[0] * 10000  # Normalize to initial investment

      ax2.plot(backtest_df.index, portfolio_value,
              label='Strategy Portfolio Value', color='#00d4aa', linewidth=2)
      ax2.plot(backtest_df.index, market_value,
              label='Buy & Hold Value', color='#0ea5e9', linestyle='--', linewidth=2)
      ax2.set_title(f'{ticker} Portfolio Performance', color='white', fontsize=16, fontweight='bold')
      ax2.set_xlabel('Date', color='white', fontsize=12)
      ax2.set_ylabel('Value ($)', color='white', fontsize=12)
      ax2.legend(fontsize=12)
      ax2.grid(True, alpha=0.3)
      ax2.tick_params(colors='white')
      ax2.spines['bottom'].set_color('white')
      ax2.spines['top'].set_color('white')
      ax2.spines['right'].set_color('white')
      ax2.spines['left'].set_color('white')

      plt.tight_layout()
      
      # Save plot if path is provided
      if save_path:
          plt.savefig(save_path, transparent=True, bbox_inches='tight', 
                     facecolor='none', edgecolor='none', dpi=150)
          plt.close()
      else:
          plt.show()

      # Calculate and print performance metrics
      initial_value = portfolio_value.iloc[0]
      final_value = portfolio_value.iloc[-1]
      total_return = (final_value / initial_value - 1) * 100
      
      # Fix market return calculation - should be based on the normalized market value, not raw price
      market_initial = market_value.iloc[0]  # This is 10000 (same as initial_value)
      market_final = market_value.iloc[-1]
      market_return = (market_final / market_initial - 1) * 100

      # Calculate Sharpe Ratio (assuming risk-free rate of 0.01)
      strategy_returns = portfolio_value.pct_change()
      excess_returns = strategy_returns - 0.01/252  # Daily risk-free rate
      sharpe_ratio = np.sqrt(252) * excess_returns.mean() / excess_returns.std()

      # Calculate Maximum Drawdown
      rolling_max = portfolio_value.expanding().max()
      drawdowns = portfolio_value/rolling_max - 1.0
      max_drawdown = drawdowns.min() * 100

      print(f"\nPerformance Metrics for {ticker}:")
      print(f"Initial Portfolio Value: ${initial_value:,.2f}")
      print(f"Final Portfolio Value: ${final_value:,.2f}")
      print(f"Strategy Total Return: {total_return:.2f}%")
      print(f"Buy & Hold Return: {market_return:.2f}%")
      print(f"Sharpe Ratio: {sharpe_ratio:.2f}")
      print(f"Maximum Drawdown: {max_drawdown:.2f}%")
      print(f"Win Rate: {(strategy_returns > 0).mean():.2%}")
      
      return {
          'total_return': total_return,
          'market_return': market_return,
          'sharpe_ratio': sharpe_ratio,
          'max_drawdown': max_drawdown,
          'win_rate': (strategy_returns > 0).mean(),
          'final_value': final_value
      }

if __name__ == "__main__":
    start_date = '2020-01-01'
    end_date = '2024-01-01'
    initial_cash = 10000

    tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'NVDA', 'TSLA', 'META']
    predictor = LSTMStockPredictor('multi_stock_model.keras', seq_length=30)

    # Training phase
    print("\nTraining phase...")
    data = predictor.fetch_and_prepare_data(tickers, start_date, end_date)
    normalized_data = predictor.normalize_data(data)
    predictor.training_tickers = tickers  # Store training tickers
    X, y, _ = predictor.create_sequences(normalized_data, tickers)
    predictor.train_save_model(X, y, tickers)

    # Backtesting phase
    print("\nBacktesting phase...")
    for ticker in tickers:
        # Pass tickers instead of initial_cash as the last parameter
        results = predictor.backtest_stock(ticker, start_date, end_date, tickers)
        if results is not None:
            predictor.plot_results(results, ticker, start_date, end_date)